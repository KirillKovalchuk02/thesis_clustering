{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d97807d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kirill\\Documents\\Projects\\thesis\\venv312\\Lib\\site-packages\\tslearn\\bases\\bases.py:15: UserWarning: h5py not installed, hdf5 features will not be supported.\n",
      "Install h5py to use hdf5 features: http://docs.h5py.org/\n",
      "  warn(h5py_msg)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random \n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from functions import join_stocks_crypto, generate_rand_portfolios\n",
    "from functions_post_clustering import reoptimize_weights, dunn_bonferroni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2c3f6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kirill\\AppData\\Local\\Temp\\ipykernel_6648\\2603468344.py:20: FutureWarning: The default fill_method='pad' in DataFrame.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  returns_all_24 = joined_df_24.pct_change().dropna()\n"
     ]
    }
   ],
   "source": [
    "#GET THE DATA IN\n",
    "\n",
    "#Main part data 2022-2023\n",
    "df_all_stocks = pd.read_csv('stocks_data_FINAL.csv',index_col='Date')\n",
    "df_all_stocks.index = pd.to_datetime(df_all_stocks.index)\n",
    "df_all_stocks.index = df_all_stocks.index.strftime('%Y-%m-%d')\n",
    "\n",
    "cryptos_df = pd.read_csv('cryptos_data_new.csv', index_col='timestamp')\n",
    "joined_df = join_stocks_crypto(cryptos_df, df_all_stocks, mode = 'stocks_left')\n",
    "joined_df.index = pd.to_datetime(joined_df.index)\n",
    "returns_all = joined_df.pct_change().dropna()\n",
    "\n",
    "tickers_to_select = list(joined_df.columns)\n",
    "#Out-of-sample data 2024:\n",
    "df_stocks_24 = pd.read_csv('stocks_data_out_sample_2024_FINAL.csv',index_col='Date')\n",
    "cryptos_df_24 = pd.read_csv('cryptos_data_out_sample_2024.csv', index_col='timestamp')\n",
    "joined_df_24 = join_stocks_crypto(cryptos_df_24, df_stocks_24, mode = 'stocks_left')\n",
    "joined_df_24 = joined_df_24[tickers_to_select]\n",
    "joined_df_24.index = pd.to_datetime(joined_df_24.index)\n",
    "returns_all_24 = joined_df_24.pct_change().dropna()\n",
    "\n",
    "\n",
    "tickers = list(df_all_stocks.columns)\n",
    "\n",
    "random.seed(42)\n",
    "random_portfolios = generate_rand_portfolios(n_reps=1000, n_stocks=15, tickers=tickers)\n",
    "\n",
    "with open('equalw_sets.json') as f:\n",
    "    equalw_sets = json.load(f)\n",
    "\n",
    "with open('mdr_reoptimized_sets.json') as f:\n",
    "    mdr_reoptimized_sets = json.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72e0599d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compare_crypto_overlap(portfolio1, portfolio2, crypto_assets):\n",
    "#     \"\"\"\n",
    "#     Compare crypto overlap between two portfolios.\n",
    "    \n",
    "#     Parameters:\n",
    "#     -----------\n",
    "#     portfolio1, portfolio2 : list or dict\n",
    "#         Portfolio assets (if dict, uses keys)\n",
    "#     crypto_assets : list\n",
    "#         List of crypto tickers to filter for\n",
    "    \n",
    "#     Returns:\n",
    "#     --------\n",
    "#     dict\n",
    "#         Overlap statistics and details\n",
    "#     \"\"\"\n",
    "#     # Extract assets from portfolios\n",
    "#     if isinstance(portfolio1, dict):\n",
    "#         assets1 = list(portfolio1.keys())\n",
    "#     else:\n",
    "#         print(\"AAAA\")\n",
    "#     #     assets1 = portfolio1\n",
    "        \n",
    "#     if isinstance(portfolio2, dict):\n",
    "#         assets2 = list(portfolio2.keys())\n",
    "#     else:\n",
    "#         assets2 = portfolio2\n",
    "    \n",
    "#     # Filter for cryptos only\n",
    "#     cryptos1 = set([asset for asset in assets1 if asset in crypto_assets])\n",
    "#     cryptos2 = set([asset for asset in assets2 if asset in crypto_assets])\n",
    "    \n",
    "#     # Calculate overlap\n",
    "#     intersection = cryptos1 & cryptos2\n",
    "#     union = cryptos1 | cryptos2\n",
    "    \n",
    "#     # Calculate metrics\n",
    "#     jaccard = len(intersection) / len(union) if len(union) > 0 else 0\n",
    "#     overlap_pct = len(intersection) / min(len(cryptos1), len(cryptos2)) if min(len(cryptos1), len(cryptos2)) > 0 else 0\n",
    "    \n",
    "#     output =  {\n",
    "#         'cryptos_portfolio1': sorted(list(cryptos1)),\n",
    "#         'cryptos_portfolio2': sorted(list(cryptos2)),\n",
    "#         'common_cryptos': sorted(list(intersection)),\n",
    "#         'unique_to_p1': sorted(list(cryptos1 - cryptos2)),\n",
    "#         'unique_to_p2': sorted(list(cryptos2 - cryptos1)),\n",
    "#         'overlap_count': len(intersection),\n",
    "#         'jaccard_similarity': jaccard,\n",
    "#         'overlap_percentage': overlap_pct\n",
    "#     }\n",
    "\n",
    "#     if len(sorted(list(intersection))) < 3:\n",
    "#         print('YES')\n",
    "#     return \n",
    "\n",
    "# CRYPTO_ASSETS = list(cryptos_df.columns)\n",
    "\n",
    "# for i in range(1000):\n",
    "#     kmeans_port = crypto_supplemented_sets['kmeans_crypto'][f'portfolio_{i}']\n",
    "#     kshape_port = crypto_supplemented_sets['kshape_crypto'][f'portfolio_{i}']\n",
    "\n",
    "#     output = compare_crypto_overlap(kmeans_port, kshape_port, CRYPTO_ASSETS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b0a8d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average df: 11.13, Min df: 5.71\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "from functions_post_clustering import estimate_t_df_for_portfolio\n",
    "import math\n",
    "\n",
    "df_estimate = math.floor(estimate_t_df_for_portfolio(returns_all))\n",
    "print(df_estimate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130b740f",
   "metadata": {},
   "source": [
    "SIMULATE AND EVALUATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c66ea3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FULL CLAUDE GENERATION CODE\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.stats import mstats, normaltest\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta\n",
    "import random\n",
    "\n",
    "# Missing function: calculate_cumulative_returns\n",
    "def calculate_cumulative_returns(returns):\n",
    "    \"\"\"\n",
    "    Calculate cumulative returns from daily returns.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    returns : numpy.ndarray\n",
    "        Array of daily returns\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    numpy.ndarray\n",
    "        Cumulative returns\n",
    "    \"\"\"\n",
    "    return np.cumprod(1 + returns, axis=0) - 1\n",
    "\n",
    "# Missing function: calculate_var_cvar\n",
    "def calculate_var_cvar(returns, confidence_level=0.05, initial_value=100):\n",
    "    \"\"\"\n",
    "    Calculate Value at Risk (VaR) and Conditional Value at Risk (CVaR)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    returns : numpy.ndarray\n",
    "        Array of daily returns\n",
    "    confidence_level : float\n",
    "        Confidence level for VaR calculation (default: 0.05)\n",
    "    initial_value : float\n",
    "        Initial portfolio value (default: 100)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        (VaR, CVaR)\n",
    "    \"\"\"\n",
    "    VaR = abs(np.percentile(returns, confidence_level * 100)) * initial_value\n",
    "    worst_losses = returns[returns <= -VaR/initial_value]\n",
    "    CVaR = abs(worst_losses.mean()) * initial_value if len(worst_losses) > 0 else VaR\n",
    "    \n",
    "    return VaR, CVaR\n",
    "\n",
    "def run_simulation(portfolio_dict, returns_for_portfolio, n_sims=100, t=100, \n",
    "                  distribution_model='multivar_norm', plot=False, initialPortfolio=100, \n",
    "                  winsorize=False, winsorize_limits=(0.01, 0.01), use_log_returns=False):\n",
    "    \"\"\"\n",
    "    Run Monte Carlo simulation for portfolio returns.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    portfolio_dict : dict\n",
    "        Dictionary with tickers as keys and weights as values\n",
    "    returns_for_portfolio : pandas.DataFrame\n",
    "        DataFrame with dates as index and tickers as columns containing returns\n",
    "    n_sims : int\n",
    "        Number of simulations to run\n",
    "    t : int\n",
    "        Number of time periods to simulate\n",
    "    distribution_model : str\n",
    "        Distribution model to use ('multivar_norm', 'multivar_t', 'bootstrap')\n",
    "    plot : bool\n",
    "        Whether to plot the simulation results\n",
    "    initialPortfolio : float\n",
    "        Initial portfolio value\n",
    "    winsorize : bool\n",
    "        Whether to winsorize returns\n",
    "    winsorize_limits : tuple\n",
    "        Limits for winsorization\n",
    "    use_log_returns : bool\n",
    "        Whether to use log returns (for consistency with out-of-sample analysis)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    numpy.ndarray\n",
    "        Simulated portfolio paths\n",
    "    \"\"\"\n",
    "    returns_for_portfolio = returns_for_portfolio[list(portfolio_dict.keys())]\n",
    "    \n",
    "    if winsorize:\n",
    "        winsorized_returns = returns_for_portfolio.copy()\n",
    "        \n",
    "        for col in winsorized_returns.columns:\n",
    "            winsorized_returns[col] = mstats.winsorize(winsorized_returns[col], limits=winsorize_limits)\n",
    "        \n",
    "        returns_for_portfolio = winsorized_returns\n",
    "\n",
    "    # Convert to log returns if specified (for consistency with out-of-sample)\n",
    "    if use_log_returns:\n",
    "        invalid_mask = returns_for_portfolio <= -1.0\n",
    "        if invalid_mask.any().any():\n",
    "            log_compatible_returns = returns_for_portfolio.copy()\n",
    "            log_compatible_returns[invalid_mask] = -0.99\n",
    "            log_returns = np.log(1 + log_compatible_returns)\n",
    "            returns_for_portfolio = log_returns\n",
    "        else:\n",
    "            returns_for_portfolio = np.log(1 + returns_for_portfolio)\n",
    "\n",
    "    mean_returns = returns_for_portfolio.mean()\n",
    "    cov_matrix = returns_for_portfolio.cov()\n",
    "\n",
    "    weights = np.array([v for _, v in portfolio_dict.items()])\n",
    "\n",
    "    meanM = np.tile(mean_returns, (t, 1))  # Shape: (T, n_assets)\n",
    "\n",
    "    portfolio_sims = np.zeros((t, n_sims))\n",
    "\n",
    "    L = np.linalg.cholesky(cov_matrix)  # Cholesky decomposition\n",
    "\n",
    "    for sim in range(n_sims):\n",
    "        if distribution_model == 'bootstrap':\n",
    "            sampled_returns = returns_for_portfolio.bfill().sample(n=t, replace=True).values\n",
    "            portfolio_returns = sampled_returns @ weights\n",
    "        elif distribution_model in ['multivar_norm', 'multivar_t']:\n",
    "            if distribution_model == 'multivar_norm':\n",
    "                Z = np.random.normal(size=(t, len(portfolio_dict)))  # Shape: (T, n_assets)\n",
    "                daily_returns = meanM + Z @ L.T  # Shape: (T, n_assets)\n",
    "            elif distribution_model == 'multivar_t':\n",
    "                df = 11  # degrees of freedom\n",
    "                Z = np.random.normal(size=(t, len(portfolio_dict)))\n",
    "                chi2 = np.random.chisquare(df, size=(t, 1))\n",
    "                Z_t = Z / np.sqrt(chi2 / df)  # now Z_t has t-distributed marginals\n",
    "\n",
    "                daily_returns = meanM + Z_t @ L.T\n",
    "\n",
    "            portfolio_returns = daily_returns @ weights  # Shape: (T,)\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "        # Convert back from log returns if necessary\n",
    "        if use_log_returns:\n",
    "            portfolio_returns = np.exp(portfolio_returns) - 1\n",
    "        \n",
    "        portfolio_sims[:, sim] = np.cumprod(1 + portfolio_returns) * initialPortfolio\n",
    "\n",
    "    if plot:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(portfolio_sims)\n",
    "        plt.title(\"Monte Carlo Simulated Portfolio Paths\")\n",
    "        plt.xlabel(\"Days\")\n",
    "        plt.ylabel(\"Portfolio Value\")\n",
    "        plt.show()\n",
    "\n",
    "    return portfolio_sims\n",
    "\n",
    "def out_of_sample_analysis(portfolio, return_data, start_date, period=126, \n",
    "                          calculate_metrics=True, plot_results=False, risk_free_rate=0.02, \n",
    "                          use_log_returns=False):\n",
    "    \"\"\"\n",
    "    Perform traditional out-of-sample analysis for a portfolio over a specified forward period.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    portfolio : dict\n",
    "        Dictionary with tickers as keys and weights as values\n",
    "    return_data : pandas.DataFrame\n",
    "        DataFrame with dates as index and tickers as columns containing RETURNS\n",
    "    start_date : str or datetime\n",
    "        Date marking the beginning of out-of-sample period\n",
    "    period : int\n",
    "        Number of days for the forward period to analyze (default 126 ~= 6 months of trading days)\n",
    "    calculate_metrics : bool\n",
    "        Whether to calculate and return performance metrics\n",
    "    plot_results : bool\n",
    "        Whether to generate and return performance plots\n",
    "    risk_free_rate : float\n",
    "        Annual risk-free rate used for Sharpe ratio calculation\n",
    "    use_log_returns : bool\n",
    "        Whether to use log returns (for consistency with simulation)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    results : dict\n",
    "        Dictionary containing performance metrics and return series for the period\n",
    "    \"\"\"\n",
    "    if isinstance(start_date, str):\n",
    "        start_date = pd.to_datetime(start_date)\n",
    "    \n",
    "    results = {}\n",
    "    tickers = list(portfolio.keys())\n",
    "    weights = np.array([portfolio[ticker] for ticker in tickers])\n",
    "    \n",
    "    missing_tickers = [ticker for ticker in tickers if ticker not in return_data.columns]\n",
    "    if missing_tickers:\n",
    "        raise ValueError(f\"The following tickers are missing from return_data: {missing_tickers}\")\n",
    "    \n",
    "    return_subset = return_data[tickers].copy()\n",
    "    return_subset = return_subset.sort_index()\n",
    "    oos_data = return_subset[return_subset.index >= start_date]\n",
    "    \n",
    "    if oos_data.empty:\n",
    "        raise ValueError(f\"No data available after start_date: {start_date}\")\n",
    "    \n",
    "    period_data = oos_data.iloc[:period]\n",
    "    returns = period_data.copy()\n",
    "\n",
    "    if use_log_returns:\n",
    "        # Handle potential invalid values for log transformation\n",
    "        invalid_mask = returns <= -1.0\n",
    "        if invalid_mask.any().any():\n",
    "            log_compatible_returns = returns.copy()\n",
    "            log_compatible_returns[invalid_mask] = -0.99  # Cap extreme losses\n",
    "            log_returns = np.log(1 + log_compatible_returns)\n",
    "        else:\n",
    "            log_returns = np.log(1 + returns)\n",
    "            \n",
    "        portfolio_log_returns = log_returns.dot(weights)\n",
    "        \n",
    "        # Convert back to simple returns for statistics\n",
    "        portfolio_returns = np.exp(portfolio_log_returns) - 1\n",
    "        \n",
    "        # Calculate cumulative returns properly from log returns\n",
    "        cumulative_returns = np.exp(portfolio_log_returns.cumsum()) - 1\n",
    "    else:\n",
    "        # Simple returns method\n",
    "        portfolio_returns = returns.dot(weights)\n",
    "        cumulative_returns = (1 + portfolio_returns).cumprod() - 1\n",
    "\n",
    "    results = {\n",
    "        'returns': portfolio_returns,\n",
    "        'cumulative_returns': cumulative_returns\n",
    "    }\n",
    "    \n",
    "    if calculate_metrics:\n",
    "        total_return = cumulative_returns.iloc[-1] if len(cumulative_returns) > 0 else 0\n",
    "        trading_days = min(len(portfolio_returns), 252)\n",
    "        \n",
    "        # Annualization factor\n",
    "        annual_factor = 252 / trading_days\n",
    "        annualized_return = (1 + total_return) ** annual_factor - 1\n",
    "\n",
    "        volatility = portfolio_returns.std() * np.sqrt(252)\n",
    "        sharpe_ratio = (annualized_return - risk_free_rate) / volatility if volatility > 0 else 0\n",
    "        \n",
    "        # Non-annualized Sharpe ratio for the period\n",
    "        rf_period = risk_free_rate * trading_days / 252\n",
    "        volatility_period = portfolio_returns.std() * np.sqrt(trading_days)\n",
    "        sharpe_period = (total_return - rf_period) / volatility_period if volatility_period > 0 else 0\n",
    "        \n",
    "        # Calculate VaR\n",
    "        var_95 = abs(portfolio_returns.quantile(0.05)) * 100\n",
    "        \n",
    "        results.update({\n",
    "            'mean_period_return': total_return,\n",
    "            'annualised_return': annualized_return,\n",
    "            'sharpe_annualized': sharpe_ratio,\n",
    "            'sharpe_period': sharpe_period,\n",
    "            'var_95': var_95,\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def calculate_diversification_ratio(portfolio_dict, return_df):\n",
    "    \"\"\"\n",
    "    Calculate the diversification ratio for a portfolio.\n",
    "    \n",
    "    Diversification Ratio = (Weighted Average of Individual Asset Volatilities) / (Portfolio Volatility)\n",
    "    \n",
    "    A ratio > 1 indicates diversification benefits (portfolio volatility < weighted average of individual volatilities)\n",
    "    A ratio = 1 indicates no diversification benefits (perfect correlation)\n",
    "    A ratio < 1 is theoretically impossible for long-only portfolios\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    portfolio_dict : dict\n",
    "        Dictionary mapping ticker symbols to weights\n",
    "    return_df : pandas.DataFrame\n",
    "        DataFrame with returns data\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        Diversification ratio\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get the assets in the portfolio\n",
    "        assets = list(portfolio_dict.keys())\n",
    "        weights = np.array([portfolio_dict[asset] for asset in assets])\n",
    "        \n",
    "        # Filter return data to only include portfolio assets\n",
    "        portfolio_returns = return_df[assets].dropna()\n",
    "        \n",
    "        if len(portfolio_returns) < 30:  # Need minimum data for reliable volatility estimates\n",
    "            return np.nan\n",
    "        \n",
    "        # Calculate individual asset volatilities (annualized)\n",
    "        individual_volatilities = portfolio_returns.std() * np.sqrt(252)\n",
    "        \n",
    "        # Calculate weighted average of individual volatilities\n",
    "        weighted_avg_volatility = np.sum(weights * individual_volatilities)\n",
    "        \n",
    "        # Calculate portfolio returns\n",
    "        portfolio_return_series = (portfolio_returns * weights).sum(axis=1)\n",
    "        \n",
    "        # Calculate portfolio volatility (annualized)\n",
    "        portfolio_volatility = portfolio_return_series.std() * np.sqrt(252)\n",
    "        \n",
    "        # Calculate diversification ratio\n",
    "        if portfolio_volatility > 0:\n",
    "            diversification_ratio = weighted_avg_volatility / portfolio_volatility\n",
    "            return diversification_ratio\n",
    "        else:\n",
    "            return np.nan\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating diversification ratio: {e}\")\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def simulate_evaluate_portfolio_subset(portfolios_subset, return_df, n_sims=100, t=100, \n",
    "                                      distribution_model='multivar_norm', rf_annual=0.04, \n",
    "                                      seed=30, winsorize=False, winsorize_limits=(0.01, 0.01),\n",
    "                                      use_log_returns=False):\n",
    "    \"\"\"\n",
    "    Simulate and evaluate a subset of portfolios.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    portfolios_subset : dict\n",
    "        Dictionary of dictionaries, where the outer keys are portfolio identifiers\n",
    "        and the inner dictionaries are ticker->weight mappings\n",
    "    return_df : pandas.DataFrame\n",
    "        DataFrame with dates as index and tickers as columns containing RETURNS\n",
    "    n_sims : int\n",
    "        Number of simulations to run for each portfolio\n",
    "    t : int\n",
    "        Number of time periods to simulate\n",
    "    distribution_model : str\n",
    "        Distribution model to use ('multivar_norm', 'multivar_t', 'bootstrap', 'out_sample_direct')\n",
    "    rf_annual : float\n",
    "        Annual risk-free rate\n",
    "    seed : int\n",
    "        Random seed for reproducibility\n",
    "    winsorize : bool\n",
    "        Whether to winsorize returns\n",
    "    winsorize_limits : tuple\n",
    "        Limits for winsorization\n",
    "    use_log_returns : bool\n",
    "        Whether to use log returns for consistency between methods\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        (simulation_results, statistics, normality_test_results)\n",
    "    \"\"\"\n",
    "    simulations_results_dict = dict()\n",
    "    subset_statistics_df = pd.DataFrame()\n",
    "\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    for i, portfolio_dict in portfolios_subset.items():\n",
    "        # Making sure weights sum up to 1\n",
    "        total = sum(portfolio_dict.values())\n",
    "        portfolio_dict = {k: v / total for k, v in portfolio_dict.items()}\n",
    "        \n",
    "        # Calculate diversification ratio for this portfolio\n",
    "        diversification_ratio = calculate_diversification_ratio(portfolio_dict, return_df)\n",
    "\n",
    "        if distribution_model == 'out_sample_direct':\n",
    "        \n",
    "            res = out_of_sample_analysis(\n",
    "                portfolio_dict, \n",
    "                return_df, \n",
    "                '2024-01-01', \n",
    "                period=t, \n",
    "                calculate_metrics=True, \n",
    "                risk_free_rate=rf_annual, \n",
    "                plot_results=False, \n",
    "                use_log_returns=use_log_returns\n",
    "            )\n",
    "            \n",
    "            mean_annual_return = res['annualised_return']\n",
    "            mean_return = res['mean_period_return']\n",
    "            sharpe_annual = res['sharpe_annualized']\n",
    "            VaR_final = res['var_95']\n",
    "            sharpe_period = res['sharpe_period']\n",
    "\n",
    "            stat_results = pd.DataFrame({\n",
    "                'annualised_return': [mean_annual_return],\n",
    "                'mean_period_return': [mean_return],\n",
    "                'sharpe_annualized': [sharpe_annual],\n",
    "                'sharpe_period': [sharpe_period],\n",
    "                'VaR': [VaR_final],\n",
    "                'diversification_ratio': [diversification_ratio],\n",
    "            })\n",
    "            \n",
    "            subset_statistics_df = pd.concat([subset_statistics_df, stat_results])\n",
    "            \n",
    "        else:\n",
    "            # Run simulation with consistent parameters\n",
    "            portfolio_sims = run_simulation(\n",
    "                portfolio_dict, \n",
    "                return_df[list(portfolio_dict.keys())], \n",
    "                n_sims=n_sims, \n",
    "                t=t, \n",
    "                distribution_model=distribution_model, \n",
    "                plot=False, \n",
    "                winsorize=winsorize, \n",
    "                winsorize_limits=winsorize_limits,\n",
    "                use_log_returns=use_log_returns\n",
    "            )\n",
    "\n",
    "            simulations_results_dict[i] = portfolio_sims\n",
    "            \n",
    "            daily_returns = (portfolio_sims[1:, :] - portfolio_sims[:-1, :]) / portfolio_sims[:-1, :]\n",
    "            \n",
    "            # For each simulation path, calculate key metrics\n",
    "            all_stats = []\n",
    "            \n",
    "            for sim in range(n_sims):\n",
    "                # Get the returns for this simulation\n",
    "                sim_returns = daily_returns[:, sim]\n",
    "                \n",
    "                # Calculate cumulative return for the period\n",
    "                final_value = portfolio_sims[-1, sim]\n",
    "                initial_value = 100\n",
    "                total_return = (final_value - initial_value) / initial_value\n",
    "                \n",
    "                # Calculate trading days (consistent with out-of-sample)\n",
    "                trading_days = min(len(sim_returns), 252)\n",
    "                \n",
    "                # Annualization factor\n",
    "                annual_factor = 252 / trading_days\n",
    "                annualized_return = (1 + total_return) ** annual_factor - 1\n",
    "                \n",
    "                # Calculate volatility (annualized)\n",
    "                volatility = sim_returns.std() * np.sqrt(252)\n",
    "                \n",
    "                # Calculate Sharpe ratio (annualized)\n",
    "                sharpe_annual = (annualized_return - rf_annual) / volatility if volatility > 0 else 0\n",
    "                \n",
    "                # Calculate period Sharpe ratio\n",
    "                rf_period = rf_annual * trading_days / 252\n",
    "                volatility_period = sim_returns.std() * np.sqrt(trading_days)\n",
    "                sharpe_period = (total_return - rf_period) / volatility_period if volatility_period > 0 else 0\n",
    "                \n",
    "                # Calculate VaR\n",
    "                var_95 = abs(np.percentile(sim_returns, 5)) * 100\n",
    "                \n",
    "                all_stats.append({\n",
    "                    'annualised_return': annualized_return,\n",
    "                    'mean_period_return': total_return,\n",
    "                    'sharpe_annualized': sharpe_annual,\n",
    "                    'sharpe_period': sharpe_period,\n",
    "                    'VaR': var_95\n",
    "                })\n",
    "            \n",
    "            # Convert all simulations to a dataframe\n",
    "            sim_stats_df = pd.DataFrame(all_stats)\n",
    "            \n",
    "            # Calculate averages across all simulations\n",
    "            mean_annual_return = sim_stats_df['annualised_return'].mean()\n",
    "            mean_return = sim_stats_df['mean_period_return'].mean()\n",
    "            mean_sharpe_annual = sim_stats_df['sharpe_annualized'].mean()\n",
    "            mean_sharpe_period = sim_stats_df['sharpe_period'].mean()\n",
    "            mean_var = sim_stats_df['VaR'].mean()\n",
    "            \n",
    "            stat_results = pd.DataFrame({\n",
    "                'annualised_return': [mean_annual_return],\n",
    "                'mean_period_return': [mean_return],\n",
    "                'sharpe_annualized': [mean_sharpe_annual],\n",
    "                'sharpe_period': [mean_sharpe_period],\n",
    "                'VaR': [mean_var],\n",
    "                'diversification_ratio': [diversification_ratio],\n",
    "            })\n",
    "\n",
    "            subset_statistics_df = pd.concat([subset_statistics_df, stat_results])\n",
    "\n",
    "    subset_statistics_df = subset_statistics_df.reset_index(drop=True)\n",
    "\n",
    "    # Run normality test (including diversification ratio)\n",
    "    results_normality_test = {}\n",
    "    for col in subset_statistics_df.columns:\n",
    "        stat, p_value = normaltest(subset_statistics_df[col])\n",
    "        results_normality_test[col] = {'statistic': stat, 'p_value': p_value}\n",
    "\n",
    "    normality_results_df = pd.DataFrame(results_normality_test).T\n",
    "    normality_results_df['normal'] = normality_results_df['p_value'] > 0.05\n",
    "\n",
    "    return simulations_results_dict, subset_statistics_df, normality_results_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cb9ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done for mdr_sets_bootstrap_t126, moving on\n",
      "Done for mdr_sets_bootstrap_t189, moving on\n",
      "Done for mdr_sets_bootstrap_t252, moving on\n",
      "Done for mdr_sets_multivar_t_t126, moving on\n",
      "Done for mdr_sets_multivar_t_t189, moving on\n",
      "Done for mdr_sets_multivar_t_t252, moving on\n",
      "Done for equalw_sets_bootstrap_t126, moving on\n",
      "Done for equalw_sets_bootstrap_t189, moving on\n",
      "Done for equalw_sets_bootstrap_t252, moving on\n",
      "Done for equalw_sets_multivar_t_t126, moving on\n",
      "Done for equalw_sets_multivar_t_t189, moving on\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "folder_overall = 'NEW_RESULTS_FINAL/'\n",
    "n_sims = 1000\n",
    "data_returns = returns_all\n",
    "data_name = 'simulation'\n",
    "distribution_models = ['bootstrap', 'multivar_t']\n",
    "time_periods = [126, 189, 252]\n",
    "portfolio_sets_group = {'mdr_sets': mdr_reoptimized_sets, 'equalw_sets': equalw_sets}\n",
    "windsorize = False\n",
    "folder = 'simulation_results_no_windsor_log_returns_right_df_1000'\n",
    "\n",
    "\n",
    "MODE = 'SIMULATION' \n",
    "\n",
    "\n",
    "if MODE == 'OUT_OF_SAMPLE_DIRECT':\n",
    "    data_returns = returns_all_24\n",
    "    data_name = 'out_sample_direct'\n",
    "    distribution_models = ['out_sample_direct']\n",
    "    windsorize = False\n",
    "    folder = 'out_of_sample_direct_results_new_1000'\n",
    "\n",
    "folder = folder_overall + folder\n",
    "# Make sure output folders exist\n",
    "os.makedirs(f'{folder}', exist_ok=True)\n",
    "\n",
    "for set_name, set_itself in portfolio_sets_group.items():\n",
    "    for distribution_model in distribution_models:\n",
    "        for time_period in time_periods:\n",
    "            subset_statistics_results_dfs = dict()\n",
    "            normality_results_dfs = dict()\n",
    "            results_all_df = pd.DataFrame()\n",
    "\n",
    "            for key, portfolio_set in set_itself.items():\n",
    "                simulations_results_dict, subset_statistics_df, normality = simulate_evaluate_portfolio_subset(\n",
    "                    portfolio_set,\n",
    "                    data_returns,\n",
    "                    n_sims=n_sims,\n",
    "                    t=time_period,\n",
    "                    distribution_model=distribution_model,\n",
    "                    winsorize=windsorize,\n",
    "                    winsorize_limits=(0.01, 0.01),\n",
    "                    use_log_returns=True\n",
    "                )\n",
    "\n",
    "                # Initialize nested dicts\n",
    "                subset_statistics_results_dfs.setdefault(time_period, {})\n",
    "                normality_results_dfs.setdefault(time_period, {})\n",
    "\n",
    "                subset_statistics_results_dfs[time_period][key] = subset_statistics_df\n",
    "                normality_results_dfs[time_period][key] = normality\n",
    "\n",
    "                # Mean series and concat\n",
    "                mean_series = subset_statistics_df.mean()\n",
    "                mean_df = pd.DataFrame(mean_series, columns=[(time_period, key)])\n",
    "                mean_df.columns = pd.MultiIndex.from_tuples(mean_df.columns)\n",
    "                results_all_df = pd.concat([results_all_df, mean_df], axis=1)\n",
    "\n",
    "            # Save to CSV with clear naming\n",
    "            csv_filename = f\"{folder}/stats_{set_name}_{distribution_model}_t{time_period}.csv\"\n",
    "            results_all_df.to_csv(csv_filename)\n",
    "\n",
    "            # Run and save Dunn-Bonferroni tests\n",
    "            all_dunn_results = dict()\n",
    "            dunn_bonferroni_test_results = dunn_bonferroni(subset_statistics_results_dfs[time_period], metrics='all')\n",
    "            all_dunn_results[time_period] = dunn_bonferroni_test_results\n",
    "\n",
    "            # Save to Excel\n",
    "            excel_filename = f\"{folder}/dunn_matrix_{set_name}_{distribution_model}_t{time_period}.xlsx\"\n",
    "            with pd.ExcelWriter(excel_filename) as writer:\n",
    "                for sheet_name, df in all_dunn_results[time_period].items():\n",
    "                    df.to_excel(writer, sheet_name=sheet_name[:31])\n",
    "\n",
    "\n",
    "            print(f'Done for {set_name}_{distribution_model}_t{time_period}, moving on')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f3a9c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e24fd56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62d55d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9455ac64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
