{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d97807d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random \n",
    "import json\n",
    "\n",
    "\n",
    "from functions import join_stocks_crypto, generate_rand_portfolios\n",
    "from functions_post_clustering import simulate_evaluate_portfolio_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2c3f6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GET THE DATA IN\n",
    "df_all_stocks = pd.read_csv('stocks_data_filled.csv',index_col='Date')\n",
    "cryptos_df = pd.read_csv('cryptos_data.csv', index_col='Date')\n",
    "\n",
    "joined_df = join_stocks_crypto(cryptos_df, df_all_stocks, mode = 'stocks_left') #mode - either do left with crypto and fill NA for stocks or do left on stocks and leave out some dates for cryptos\n",
    "joined_df.index = pd.to_datetime(joined_df.index)\n",
    "\n",
    "returns_all = joined_df.pct_change()\n",
    "\n",
    "\n",
    "tickers = list(df_all_stocks.columns)\n",
    "\n",
    "random.seed(42)\n",
    "random_portfolios = generate_rand_portfolios(n_reps=1000, n_stocks=15, tickers=tickers)\n",
    "\n",
    "\n",
    "#Reassemble the portfolio jsons for minvar\n",
    "min_var_portfolios = dict()\n",
    "for i in range(1,1000):\n",
    "    with open(f'min_variance_portfolio_jsons/my_dict{i}.json') as f:\n",
    "        port = json.load(f)\n",
    "        min_var_portfolios.update(port)\n",
    "\n",
    "with open(f\"full_optimized_min_variance.json\", \"w\") as f:\n",
    "    json.dump(min_var_portfolios, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130b740f",
   "metadata": {},
   "source": [
    "SIMULATE AND EVALUATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bed36ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           statistic        p_value  normal\n",
      "mean_cumulative_return    618.729744  4.411062e-135   False\n",
      "mean_daily_return         618.729744  4.411062e-135   False\n",
      "std_cumulative_return     787.286530  1.103830e-171   False\n",
      "std_daily_return          775.100921  4.886225e-169   False\n",
      "sharpe_daily                5.107170   7.780225e-02    True\n",
      "sharpe_cumulative           6.063570   4.822946e-02   False\n",
      "sharpe_annual               5.107170   7.780225e-02    True\n",
      "sharpe_cumulative_annual    6.063570   4.822946e-02   False\n",
      "VaR                       568.763064  3.123704e-124   False\n",
      "CVaR                      459.647092  1.544906e-100   False\n",
      "                           statistic        p_value  normal\n",
      "mean_cumulative_return    430.098636   4.029656e-94   False\n",
      "mean_daily_return         430.098636   4.029656e-94   False\n",
      "std_cumulative_return     564.590080  2.516644e-123   False\n",
      "std_daily_return          555.698375  2.146007e-121   False\n",
      "sharpe_daily               89.141050   4.398119e-20   False\n",
      "sharpe_cumulative          97.767960   5.887855e-22   False\n",
      "sharpe_annual              89.141050   4.398119e-20   False\n",
      "sharpe_cumulative_annual   97.767960   5.887855e-22   False\n",
      "VaR                       601.917907  1.973273e-131   False\n",
      "CVaR                      583.680429  1.800550e-127   False\n"
     ]
    }
   ],
   "source": [
    "simulations_results_dict_rand, subset_statistics_df_rand, _ = simulate_evaluate_portfolio_subset(random_portfolios, returns_all, n_sims=100, t=100, distribution_model='multivar_norm')\n",
    "\n",
    "simulations_results_dict_minvar, subset_statistics_df_minvar, _ = simulate_evaluate_portfolio_subset(min_var_portfolios, returns_all, n_sims=100, t=100, distribution_model='multivar_norm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873837aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f_oneway\n",
    "from scipy.stats import kruskal\n",
    "\n",
    "\n",
    "def kruskal_anova_test(subset_stats_dfs:list, metrics=['sharpe_annual'], test='anova'):\n",
    "    tests_results = dict()\n",
    "    for metric in metrics:\n",
    "        groups = [subset_df[metric] for subset_df in subset_stats_dfs]\n",
    "    \n",
    "        if test == 'anova':\n",
    "            test_stat, test_p = f_oneway(*groups)\n",
    "        elif test == 'kruskal':\n",
    "            test_stat, test_p = kruskal(*groups)\n",
    "\n",
    "        tests_results[metric] = {'test_stat': round(float(test_stat), 4), 'test_p': round(float(test_p), 4)}\n",
    "    \n",
    "    return pd.DataFrame(tests_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ecfc5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sharpe_annual</th>\n",
       "      <th>sharpe_cumulative_annual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test_stat</th>\n",
       "      <td>233.7857</td>\n",
       "      <td>239.2611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_p</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           sharpe_annual  sharpe_cumulative_annual\n",
       "test_stat       233.7857                  239.2611\n",
       "test_p            0.0000                    0.0000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kruskal_anova_test([subset_statistics_df_rand, subset_statistics_df_minvar], metrics=['sharpe_annual', 'sharpe_cumulative_annual'], test='kruskal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9157f775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group 1</th>\n",
       "      <th>Group 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Group 1</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>8.907910e-53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Group 2</th>\n",
       "      <td>8.907910e-53</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Group 1       Group 2\n",
       "Group 1  1.000000e+00  8.907910e-53\n",
       "Group 2  8.907910e-53  1.000000e+00"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dunn-Bonferroni Test\n",
    "import scikit_posthocs as sp\n",
    "\n",
    "\n",
    "group1 = subset_statistics_df_rand['sharpe_annual']\n",
    "group2 = subset_statistics_df_minvar['sharpe_annual']\n",
    "\n",
    "\n",
    "# Combine into one Series\n",
    "data = pd.concat([group1, group2], ignore_index=True)\n",
    "groups = ['Group 1'] * len(group1) + ['Group 2'] * len(group2)\n",
    "\n",
    "#sp.posthoc_dunn([group1, group2], p_adjust='bonferroni')\n",
    "\n",
    "df = pd.DataFrame({'value': data, 'group': groups})\n",
    "sp.posthoc_dunn(df, val_col='value', group_col='group', p_adjust='bonferroni')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c3f067",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
