{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random \n",
    "import itertools\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "pd.set_option('display.max_rows', 50)\n",
    "\n",
    "\n",
    "from functions import sharpe_ratio_calculation, generate_rand_portfolios, select_top_five, join_stocks_crypto, test_for_silhouette_score, run_clustering_model, label_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_stocks = pd.read_csv('stocks_data_filled.csv',index_col='Date')\n",
    "cryptos_df = pd.read_csv('cryptos_data.csv', index_col='Date')\n",
    "\n",
    "joined_df = join_stocks_crypto(cryptos_df, df_all_stocks, mode = 'stocks_left') #mode - either do left with crypto and fill NA for stocks or do left on stocks and leave out some dates for cryptos\n",
    "joined_df.index = pd.to_datetime(joined_df.index)\n",
    "joined_df = joined_df.bfill()\n",
    "\n",
    "joined_df_weekly = joined_df.resample('W').last() #try aggregating on a weekly level\n",
    "joined_df_3days = joined_df.resample('3D').last()# aggregating on a twice per week basis to arrive at the sweet spot of that 250 (1 year) timeseries length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Portfolios generation\n",
    "tickers = list(df_all_stocks.columns)\n",
    "\n",
    "random.seed(42)\n",
    "random_portfolios = generate_rand_portfolios(n_reps=1000, n_stocks=15, tickers=tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select top five sharpe ratio portfolios from a portfolio\n",
    "sharpe_ratio = sharpe_ratio_calculation(df_all_stocks, rf_rate_annual = 0.02)\n",
    "top_five_dict = select_top_five(random_portfolios, metric=sharpe_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimize Traditional Portfolios\n",
    "# for i in range(999, 1001):\n",
    "\n",
    "#     print('Doing', i)\n",
    "\n",
    "#     top_five_sets = dict(itertools.islice(top_five_dict.items(), i, i+1))\n",
    "#     results = run_min_variance(df_all_stocks, top_five_sets, min_weight_for_top_five=0.05)  #TRY DIFFERENT WEIGHTS FOR top_five\n",
    "#     with open(f\"min_variance_portfolio_jsons/my_dict{i}.json\", \"w\") as f:\n",
    "#         json.dump(results, f, indent=4)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Reassemble the results of the optimization - jsons\n",
    "# min_var_portfolios = dict()\n",
    "# for i in range(1,1000):\n",
    "#     with open(f'min_variance_portfolio_jsons/my_dict{i}.json') as f:\n",
    "#         port = json.load(f)\n",
    "#         min_var_portfolios.update(port)\n",
    "\n",
    "# with open(f\"full_optimized_min_variance.json\", \"w\") as f:\n",
    "#     json.dump(min_var_portfolios, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN THE CLUSTERING WITH DIFFERENT SET UPS TO GET THE SILHOUETTE SCORES FOR COMPARISON\n",
    "\n",
    "# n_clusters_list = [4,5,6,7]\n",
    "# linkage_list=['single', 'average', 'complete']\n",
    "# #window_sizes = [3,7,10,14,21,30,60]\n",
    "# window_sizes = [21,30,60]\n",
    "\n",
    "\n",
    "# def run_clustering_evaluation(df, window_sizes, method, moving_average=True, return_mode='arithmetic', df_input_name='DFWASNOTSPECIFIED'):\n",
    "\n",
    "#     for w_size in window_sizes:\n",
    "\n",
    "#         #return_mode = 'arithmetic'\n",
    "#         #n_init = 3\n",
    "#         #center = True\n",
    "#         if moving_average:\n",
    "#             df = df.rolling(window=w_size, center=True).mean()\n",
    "\n",
    "#             smoothing = 'moving_average'\n",
    "#         else:\n",
    "#             smoothing = 'no_smoothing'\n",
    "\n",
    "#         if len(df) < 150 and w_size > 30:\n",
    "#             continue\n",
    "#         silhouette_df = test_for_silhouette_score(df, n_clusters_list, method=method, return_mode=return_mode, n_init=3, linkage_list=linkage_list)\n",
    "\n",
    "#         silhouette_df['return_mode'] = return_mode\n",
    "#         silhouette_df['n_init'] = 3\n",
    "#         silhouette_df['smoothing'] = smoothing\n",
    "#         silhouette_df['window_size/span'] = w_size\n",
    "\n",
    "#         silhouette_df.to_csv(f'silhouette_dfs/{method}_{smoothing}_{return_mode}_windowsize-{w_size}_{df_input_name}.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# df_input_name = input('Put in the name of the df mode you are running for: ')\n",
    "# for return_mode in ['arithmetic', 'geometric']:\n",
    "#     run_clustering_evaluation(joined_df_3days, window_sizes, method='kmeans', moving_average=True, return_mode=return_mode, df_input_name=df_input_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN FOR LABEL BALANCE\n",
    "\n",
    "method_loop = 'ahc'\n",
    "return_mode_loop = 'geometric'\n",
    "n_clus_loop = 4\n",
    "\n",
    "df_with_label_balance = pd.DataFrame()\n",
    "for df_dict in [{'weekly': joined_df_weekly}, {'3day': joined_df_3days}, {'full': joined_df}]:\n",
    "    for linkage in ['single', 'complete', 'average']:\n",
    "        for w in [3,7,10,14,30]:\n",
    "            output = label_balance(df_dict, w, method_loop, return_mode_loop, n_clus=n_clus_loop, linkage=linkage)\n",
    "            df_with_label_balance = pd.concat([df_with_label_balance, output])\n",
    "\n",
    "df_with_label_balance.reset_index(inplace=True)\n",
    "\n",
    "df_with_label_balance.to_csv(f'balance_datasets/balance_test_results_{method_loop}_{return_mode_loop}_{n_clus_loop}clusters.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
