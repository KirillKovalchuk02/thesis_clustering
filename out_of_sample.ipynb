{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb668ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kirill\\Documents\\Projects\\thesis\\venv312\\Lib\\site-packages\\tslearn\\bases\\bases.py:15: UserWarning: h5py not installed, hdf5 features will not be supported.\n",
      "Install h5py to use hdf5 features: http://docs.h5py.org/\n",
      "  warn(h5py_msg)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random \n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from functions import join_stocks_crypto, generate_rand_portfolios\n",
    "from functions_post_clustering import simulate_evaluate_portfolio_subset, reoptimize_weights, kruskal_anova_test, dunn_bonferroni, run_simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30886634",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GET THE DATA IN\n",
    "df_all_stocks = pd.read_csv('stocks_data_filled.csv',index_col='Date')\n",
    "cryptos_df = pd.read_csv('cryptos_data_new.csv', index_col='timestamp')\n",
    "joined_df = join_stocks_crypto(cryptos_df, df_all_stocks, mode = 'stocks_left')\n",
    "joined_df.index = pd.to_datetime(joined_df.index)\n",
    "returns_all = joined_df.pct_change()\n",
    "\n",
    "\n",
    "\n",
    "df_stocks_24 = pd.read_csv('stocks_data_filled.csv',index_col='Date')\n",
    "cryptos_df_24 = pd.read_csv('cryptos_data_new.csv', index_col='timestamp')\n",
    "joined_df_24 = join_stocks_crypto(cryptos_df_24, df_stocks_24, mode = 'stocks_left')\n",
    "joined_df_24.index = pd.to_datetime(joined_df_24.index)\n",
    "returns_all_24 = joined_df_24.pct_change()\n",
    "\n",
    "\n",
    "tickers = list(df_all_stocks.columns)\n",
    "\n",
    "random.seed(42)\n",
    "random_portfolios = generate_rand_portfolios(n_reps=1000, n_stocks=15, tickers=tickers)\n",
    "\n",
    "\n",
    "#Reassemble the portfolio jsons for minvar\n",
    "min_var_portfolios = dict()\n",
    "for i in range(1,1000):\n",
    "    with open(f'min_variance_portfolio_jsons/my_dict{i}.json') as f:\n",
    "        port = json.load(f)\n",
    "        min_var_portfolios.update(port)\n",
    "\n",
    "\n",
    "rand_ports_standard = random_portfolios.copy()\n",
    "rand_ports_maxsharpe = reoptimize_weights(joined_df, random_portfolios, how='max_sharpe', min_weight=0.01)\n",
    "rand_ports_equal_weights = reoptimize_weights(joined_df, random_portfolios, how='equal_weights', min_weight=0.01)\n",
    "\n",
    "minvar_port_standard = min_var_portfolios.copy()\n",
    "minvar_ports_maxsharpe = reoptimize_weights(joined_df, min_var_portfolios, how='max_sharpe', min_weight=0.01)\n",
    "minvar_ports_equal_weights = reoptimize_weights(joined_df, min_var_portfolios, how='equal_weights', min_weight=0.01)\n",
    "\n",
    "\n",
    "with open('all_optimized_sets_for_simulation.json') as f:\n",
    "    crypto_supplemented_sets = json.load(f)\n",
    "\n",
    "\n",
    "portfolio_sets = {#'rand_ports_standard': rand_ports_standard,\n",
    "                  'rand_ports_maxsharpe': rand_ports_maxsharpe, \n",
    "                  'rand_ports_equalw': rand_ports_equal_weights,\n",
    "                  #'minvar_port_standard': minvar_port_standard,  \n",
    "                  'minvar_ports_maxsharpe': minvar_ports_maxsharpe, \n",
    "                  'minvar_ports_equalw': minvar_ports_equal_weights}\n",
    "\n",
    "all_sets = portfolio_sets | crypto_supplemented_sets\n",
    "\n",
    "equalw_sets = {k: v for k, v in all_sets.items() if 'equalw' in k}\n",
    "maxsharpe_sets = {k: v for k, v in all_sets.items() if 'equalw' not in k}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75336ca6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbde6fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions_post_clustering import simulate_evaluate_portfolio_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d30898",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulate_evaluate_portfolio_subset(portfolios_subset=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3bc43f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9205ef02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9c9762",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb06c27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1bb01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate_portfolios_out_of_sample(portfolios_subset, out_of_sample_returns, n_sims=1000, \n",
    "#                                      winsorize=True, winsorize_limits=(0.01, 0.01)):\n",
    "#     \"\"\"\n",
    "#     Evaluate a set of portfolios using out-of-sample return data\n",
    "    \n",
    "#     Parameters:\n",
    "#     - portfolios_subset: Dictionary of portfolios {portfolio_id: {ticker: weight}}\n",
    "#     - out_of_sample_returns: DataFrame with out-of-sample return data\n",
    "#     - n_sims: Number of simulations to run\n",
    "#     - winsorize: Whether to winsorize returns\n",
    "#     - winsorize_limits: Limits for winsorizing\n",
    "    \n",
    "#     Returns:\n",
    "#     - DataFrame with performance metrics for each portfolio\n",
    "#     \"\"\"\n",
    "#     results = {}\n",
    "    \n",
    "#     for portfolio_id, portfolio_dict in portfolios_subset.items():\n",
    "#         # Identify tickers in this portfolio\n",
    "#         portfolio_tickers = list(portfolio_dict.keys())\n",
    "        \n",
    "#         # Check if all tickers are in the out-of-sample data\n",
    "#         missing_tickers = set(portfolio_tickers) - set(out_of_sample_returns.columns)\n",
    "#         if missing_tickers:\n",
    "#             print(f\"Portfolio {portfolio_id}: Missing tickers {missing_tickers}. Skipping.\")\n",
    "#             continue\n",
    "        \n",
    "#         # Run simulation with out-of-sample data\n",
    "#         t = len(out_of_sample_returns)  # Use full length of out-of-sample data\n",
    "#         portfolio_sims = run_simulation(\n",
    "#             portfolio_dict, \n",
    "#             out_of_sample_returns, \n",
    "#             n_sims=n_sims, \n",
    "#             t=t,\n",
    "#             distribution_model='bootstrap',  # Bootstrap from out-of-sample data\n",
    "#             winsorize=winsorize,\n",
    "#             winsorize_limits=winsorize_limits\n",
    "#         )\n",
    "        \n",
    "#         # Calculate performance metrics\n",
    "#         # 1. Total Return\n",
    "#         initial_value = 100\n",
    "#         final_values = portfolio_sims[-1, :]\n",
    "#         total_returns = (final_values / initial_value) - 1\n",
    "        \n",
    "#         # 2. Properly calculated annualized returns\n",
    "#         years = t / 252\n",
    "#         annualized_returns = (final_values / initial_value) ** (1 / years) - 1\n",
    "        \n",
    "#         # 3. Daily returns for risk calculations\n",
    "#         daily_returns = (portfolio_sims[1:, :] - portfolio_sims[:-1, :]) / portfolio_sims[:-1, :]\n",
    "        \n",
    "#         # 4. Volatility (annualized)\n",
    "#         volatility = np.std(daily_returns, axis=0) * np.sqrt(252)\n",
    "        \n",
    "#         # 5. Sharpe Ratio (assuming risk-free rate of 0.02 annual, or about 0.00008 daily)\n",
    "#         rf_annual = 0.02\n",
    "#         rf_daily = rf_annual / 252\n",
    "#         sharpe_ratio = (np.mean(daily_returns, axis=0) - rf_daily) / np.std(daily_returns, axis=0) * np.sqrt(252)\n",
    "        \n",
    "#         # 6. Maximum Drawdown\n",
    "#         max_drawdowns = np.zeros(n_sims)\n",
    "#         for sim in range(n_sims):\n",
    "#             peak = np.maximum.accumulate(portfolio_sims[:, sim])\n",
    "#             drawdown = (portfolio_sims[:, sim] - peak) / peak\n",
    "#             max_drawdowns[sim] = np.min(drawdown)\n",
    "        \n",
    "#         # 7. Sortino Ratio\n",
    "#         downside_returns = np.minimum(daily_returns - rf_daily, 0)\n",
    "#         downside_deviation = np.sqrt(np.mean(np.square(downside_returns), axis=0))\n",
    "#         sortino_ratio = (np.mean(daily_returns, axis=0) - rf_daily) / downside_deviation * np.sqrt(252)\n",
    "        \n",
    "#         # 8. Value at Risk (95%)\n",
    "#         var_95 = np.percentile(daily_returns, 5, axis=0) * initial_value\n",
    "        \n",
    "#         # Store results for this portfolio\n",
    "#         results[portfolio_id] = {\n",
    "#             'mean_total_return': np.mean(total_returns),\n",
    "#             'mean_annualized_return': np.mean(annualized_returns),\n",
    "#             'mean_volatility': np.mean(volatility),\n",
    "#             'mean_sharpe_ratio': np.mean(sharpe_ratio),\n",
    "#             'mean_sortino_ratio': np.mean(sortino_ratio),\n",
    "#             'mean_max_drawdown': np.mean(max_drawdowns),\n",
    "#             'var_95': np.mean(var_95),\n",
    "#             # Include various percentiles to understand distribution\n",
    "#             'return_10th_percentile': np.percentile(annualized_returns, 10),\n",
    "#             'return_median': np.median(annualized_returns),\n",
    "#             'return_90th_percentile': np.percentile(annualized_returns, 90)\n",
    "#         }\n",
    "    \n",
    "#     # Convert results to DataFrame\n",
    "#     results_df = pd.DataFrame(results).T\n",
    "    \n",
    "#     # Sort by Sharpe ratio (risk-adjusted performance)\n",
    "#     results_df = results_df.sort_values('mean_sharpe_ratio', ascending=False)\n",
    "    \n",
    "#     return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e71459",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
